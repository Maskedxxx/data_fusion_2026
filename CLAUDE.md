# Data Fusion 2026 — Cybershelf

## О проекте
Участие в хакатоне Data Fusion 2026, задача 2 "Киберполка".
Multi-label классификация: предсказание вероятности открытия 41 финансового продукта.

## Структура репозитория
```
data_fusion/
├── CLAUDE.md                # Инструкции для агента
├── data/
│   ├── raw/                 # Исходные данные (не трогаем, read-only)
│   │   ├── train_target.parquet          # Разметка 41 продукта (4.8MB)
│   │   ├── train_main_features.parquet   # Основные признаки train (119MB)
│   │   ├── train_extra_features.parquet  # Доп. признаки train (959MB)
│   │   ├── test_main_features.parquet    # Основные признаки test (42.4MB)
│   │   └── test_extra_features.parquet   # Доп. признаки test (320MB)
│   └── processed/           # Обработанные фичи, сплиты, кэши
├── notebooks/               # EDA и эксперименты (Jupyter)
│   ├── exp011_optuna/       # EXP-011: Optuna + стекинг (LB 0.8472, лучший)
│   │   ├── exp011_optuna_stacking.ipynb  # Полный пайплайн
│   │   └── artifacts/       # Артефакты с Colab (npy, json, parquet)
│   ├── exp009_stacking.ipynb             # EXP-009: стекинг (LB 0.8444)
│   └── ...                  # Другие ноутбуки
├── insights/                # Документация, инсайты, журнал экспериментов
│   ├── EXPERIMENTS.md       # Журнал экспериментов EXP-001..011
│   ├── PIPELINE_EXP009.txt  # ASCII-схема пайплайна
│   ├── MEMORY.md            # Общее состояние проекта и roadmap
│   ├── baseline_insights.md # Все инсайты, параметры, артефакты
│   ├── kaggle_insights.md   # Техники из Kaggle-соревнований
│   └── hackathon_details.md # Описание хакатона
├── baseline/                # sample_submit.parquet + baseline_catboost.ipynb (не трогаем)
├── submissions/             # Готовые сабмиты .parquet
├── src/                     # Пайплайны, утилиты, скрипты .py
└── trec_cybershelf/         # (legacy)
```

## Рабочий процесс
1. **Ресёрч** — изучаем данные, baseline, подходы других участников
2. **EDA** — разведочный анализ в Jupyter ноутбуках
3. **Эксперименты** — пайплайны моделей, feature engineering
4. **Валидация** — локальная валидация macro ROC-AUC
5. **Сабмит** — формирование .parquet и отправка (лимит 5/день)

## Правила работы агента
- Все эксперименты документировать: что пробовали, какой скор получили
- Перед запуском тяжёлых вычислений — предупреждать
- Результаты экспериментов записывать в память проекта
- Код пишем чистый, но без overengineering — это соревнование, не продакшн
- Ноутбуки для EDA и экспериментов, .py скрипты для пайплайнов
- Все инсайты и находки фиксировать в памяти
- Каждый эксперимент записывать в `insights/EXPERIMENTS.md` (формат EXP-XXX, новые сверху)
- Проверенные инсайты выносить в `insights/` и `memory/`

## Правила работы с пользователем
- **Код пишем по одной ячейке** — не скидывать всё сразу, ячейка за ячейкой
- **Перед кодом — рассуждение и обоснование**: зачем эта ячейка, что делает, что ожидаем
- **Код пишем в терминале** (текстом), пользователь сам копирует в Jupyter
- **Ждём результат** — пользователь запускает ячейку и скидывает вывод
- **Переход к следующей ячейке** — только когда пользователь всё понял и подтвердил
- **НЕ редактируем ноутбук напрямую** через NotebookEdit без просьбы пользователя
- **Инсайты объясняем по одному**, не валим всё в кучу
- **baseline/ не трогаем** — это референс, рабочий ноутбук в notebooks/

## Метрика
```python
roc_auc_score(y_true, y_pred, average="macro")
```

## Окружение
- DGX Spark: ARM64, GB10, 128GB UMA
- PyTorch 2.9+cu130 (если нужны нейросети)
- Основные инструменты: LightGBM, CatBoost, pandas, scikit-learn
- venv отдельный для проекта
