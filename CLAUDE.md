# Data Fusion 2026 — Cybershelf

## О проекте
Участие в хакатоне Data Fusion 2026, задача 2 "Киберполка".
Multi-label классификация: предсказание вероятности открытия 41 финансового продукта.

## Структура репозитория
```
data_fusion/
├── CLAUDE.md                # Инструкции для агента
├── data/
│   ├── raw/                 # Исходные данные (не трогаем, read-only)
│   │   ├── train_target.parquet          # Разметка 41 продукта (4.8MB)
│   │   ├── train_main_features.parquet   # Основные признаки train (119MB)
│   │   ├── train_extra_features.parquet  # Доп. признаки train (959MB)
│   │   ├── test_main_features.parquet    # Основные признаки test (42.4MB)
│   │   └── test_extra_features.parquet   # Доп. признаки test (320MB)
│   └── processed/           # Обработанные фичи, сплиты, кэши
├── notebooks/               # EDA и эксперименты (Jupyter)
├── baseline/                # sample_submit.parquet (43.9MB) + baseline_catboost.ipynb (231KB)
├── submissions/             # Готовые сабмиты .parquet
├── src/                     # Пайплайны, утилиты, скрипты .py
└── trec_cybershelf/         # (legacy)
```

## Рабочий процесс
1. **Ресёрч** — изучаем данные, baseline, подходы других участников
2. **EDA** — разведочный анализ в Jupyter ноутбуках
3. **Эксперименты** — пайплайны моделей, feature engineering
4. **Валидация** — локальная валидация macro ROC-AUC
5. **Сабмит** — формирование .parquet и отправка (лимит 5/день)

## Правила работы агента
- Все эксперименты документировать: что пробовали, какой скор получили
- Перед запуском тяжёлых вычислений — предупреждать
- Результаты экспериментов записывать в память проекта
- Код пишем чистый, но без overengineering — это соревнование, не продакшн
- Ноутбуки для EDA и экспериментов, .py скрипты для пайплайнов
- Все инсайты и находки фиксировать в памяти
- Каждый эксперимент записывать в `EXPERIMENTS.md` (формат EXP-XXX, новые сверху)
- Проверенные инсайты выносить из EXPERIMENTS.md в `memory/`

## Правила работы с пользователем
- **Код пишем по одной ячейке** — не скидывать всё сразу, ячейка за ячейкой
- **Перед кодом — рассуждение и обоснование**: зачем эта ячейка, что делает, что ожидаем
- **Код пишем в терминале** (текстом), пользователь сам копирует в Jupyter
- **Ждём результат** — пользователь запускает ячейку и скидывает вывод
- **Переход к следующей ячейке** — только когда пользователь всё понял и подтвердил
- **НЕ редактируем ноутбук напрямую** через NotebookEdit без просьбы пользователя
- **Инсайты объясняем по одному**, не валим всё в кучу
- **baseline/ не трогаем** — это референс, рабочий ноутбук в notebooks/

## Метрика
```python
roc_auc_score(y_true, y_pred, average="macro")
```

## Окружение
- DGX Spark: ARM64, GB10, 128GB UMA
- PyTorch 2.9+cu130 (если нужны нейросети)
- Основные инструменты: LightGBM, CatBoost, pandas, scikit-learn
- venv отдельный для проекта
