{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXP-011: Optuna Per-Target Params + Стекинг\n",
    "\n",
    "**Результат: LB 0.8472** (предыдущий лучший EXP-009: 0.8445, дельта +0.0027)\n",
    "\n",
    "## Пайплайн\n",
    "1. **Optuna** — подбор гиперпараметров XGBoost для каждого из 41 таргетов (100k, 3-fold, 20 trials)\n",
    "2. **L1 OOF** — XGBoost 5-fold OOF с Optuna params + per-target feature selection (750k)\n",
    "3. **Full Train + Test Inference** — XGBoost full train 750k → predict test 250k\n",
    "4. **L2 Стекинг** — мета-модель XGBoost depth=2 на 41 OOF-фиче → финальный сабмит\n",
    "\n",
    "## Результаты\n",
    "- L1 OOF Macro AUC: **0.8407** (было 0.8352, +0.0055)\n",
    "- L2 Meta OOF Macro AUC: **0.8423**\n",
    "- **Public LB: 0.8472**\n",
    "\n",
    "## Время\n",
    "- Optuna: ~14 часов (A100, 100k × 41 таргетов × 20 trials)\n",
    "- OOF: 135 мин (A100)\n",
    "- Full train + test: 22 мин (A100)\n",
    "- L2 стекинг: <1 мин\n",
    "\n",
    "## Артефакты\n",
    "- `optuna_best_params.json` — Optuna параметры для 41 таргета\n",
    "- `xgb_oof_optuna.npy` — L1 OOF предсказания (750k, 41)\n",
    "- `xgb_best_features_optuna.json` — отобранные фичи для каждого таргета\n",
    "- `xgb_test_optuna.npy` — L1 test предсказания (250k, 41)\n",
    "- `submission_optuna_stacking.parquet` — финальный сабмит"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Шаг 0: Настройка окружения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import json, os, time, gc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "DATA = '/content/drive/MyDrive/data_fusion'\n",
    "print(f\"XGBoost version: {xgb.__version__}\")\n",
    "print(f\"CUDA available: {'cuda' in xgb.build_info().get('USE_CUDA', '')}\" if hasattr(xgb, 'build_info') else 'check manually')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Шаг 1: Optuna — подбор гиперпараметров (100k, 3-fold, 20 trials)\n",
    "\n",
    "Каждый из 41 таргетов получает свои оптимальные параметры.\n",
    "Пространство поиска: max_depth [4-10], lr [0.01-0.1], colsample [0.3-0.9], mcw [1-20], reg_alpha/lambda [1e-3..10], n_rounds [300-2000].\n",
    "\n",
    "**Время: ~14 часов на A100.**\n",
    "Чекпоинт сохраняется после каждого таргета — можно перезапускать Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Настройки Optuna ===\n",
    "SAMPLE = 100000       # Подвыборка для быстрого поиска\n",
    "N_FOLDS_OPTUNA = 3    # 3-fold для скорости\n",
    "N_TRIALS = 20         # 20 trials на таргет\n",
    "CHECKPOINT = f'{DATA}/optuna_best_params.json'\n",
    "\n",
    "# === Загрузка данных ===\n",
    "print(\"Загрузка данных...\")\n",
    "train_main = pd.read_parquet(f'{DATA}/train_main_features.parquet').head(SAMPLE)\n",
    "train_extra = pd.read_parquet(f'{DATA}/train_extra_features.parquet').head(SAMPLE)\n",
    "train_target = pd.read_parquet(f'{DATA}/train_target.parquet').head(SAMPLE)\n",
    "\n",
    "X = train_main.merge(train_extra, on='customer_id', how='left').drop(columns=['customer_id'])\n",
    "y = train_target.drop(columns=['customer_id'])\n",
    "target_columns = y.columns.tolist()\n",
    "\n",
    "X_np = np.ascontiguousarray(X.astype(np.float32).values)\n",
    "y_np = y.values\n",
    "del train_main, train_extra, train_target, X, y\n",
    "gc.collect()\n",
    "print(f\"Данные: {X_np.shape}, таргетов: {len(target_columns)}\")\n",
    "\n",
    "# === Загрузка чекпоинта (если Colab перезапускался) ===\n",
    "if os.path.exists(CHECKPOINT):\n",
    "    with open(CHECKPOINT, 'r') as f:\n",
    "        best_params_dict = json.load(f)\n",
    "    print(f\"Чекпоинт найден: {len(best_params_dict)} таргетов уже готово\")\n",
    "else:\n",
    "    best_params_dict = {}\n",
    "\n",
    "# === Базовые параметры XGBoost ===\n",
    "base_params = {\n",
    "    'objective': 'binary:logistic', 'eval_metric': 'auc',\n",
    "    'tree_method': 'hist', 'device': 'cuda', 'seed': 42, 'verbosity': 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_oof(params, n_rounds, X_data, y_target):\n",
    "    \"\"\"3-fold OOF AUC для Optuna.\"\"\"\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS_OPTUNA, shuffle=True, random_state=42)\n",
    "    oof = np.zeros(len(y_target))\n",
    "    for tr_idx, val_idx in skf.split(X_data, y_target):\n",
    "        dtrain = xgb.DMatrix(X_data[tr_idx], label=y_target[tr_idx])\n",
    "        dval = xgb.DMatrix(X_data[val_idx], label=y_target[val_idx])\n",
    "        model = xgb.train(params, dtrain, num_boost_round=n_rounds, verbose_eval=False)\n",
    "        oof[val_idx] = model.predict(dval)\n",
    "    return roc_auc_score(y_target, oof)\n",
    "\n",
    "\n",
    "# === Optuna для каждого таргета ===\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"{'Таргет':<15} {'Default':<10} {'Optuna':<10} {'Дельта':<10} {'Время':<8} {'Лучшие параметры'}\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "start_total = time.time()\n",
    "\n",
    "for t_idx, target_col in enumerate(target_columns):\n",
    "    # Пропускаем уже обученные (чекпоинт)\n",
    "    if target_col in best_params_dict:\n",
    "        p = best_params_dict[target_col]\n",
    "        print(f\"[{t_idx+1:2d}/41] {target_col:<15} ПРОПУСК (чекпоинт, Optuna AUC: {p.get('best_auc', '?')})\")\n",
    "        continue\n",
    "\n",
    "    y_target = y_np[:, t_idx]\n",
    "    n_pos = int(y_target.sum())\n",
    "    start_t = time.time()\n",
    "\n",
    "    # Защита: слишком мало позитивов\n",
    "    if n_pos < N_FOLDS_OPTUNA * 2:\n",
    "        best_params_dict[target_col] = {\n",
    "            'max_depth': 6, 'learning_rate': 0.05, 'n_rounds': 500,\n",
    "            'subsample': 0.8, 'colsample_bytree': 0.8,\n",
    "            'min_child_weight': 1, 'reg_alpha': 0.01, 'reg_lambda': 1.0,\n",
    "            'best_auc': 0.5, 'note': 'too_few_positives'\n",
    "        }\n",
    "        print(f\"[{t_idx+1:2d}/41] {target_col:<15} ПРОПУСК (pos={n_pos})\")\n",
    "        continue\n",
    "\n",
    "    # Default AUC\n",
    "    default_params = base_params.copy()\n",
    "    default_params.update({\n",
    "        'max_depth': 6, 'learning_rate': 0.05,\n",
    "        'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_weight': 5\n",
    "    })\n",
    "    auc_default = eval_oof(default_params, 500, X_np, y_target)\n",
    "\n",
    "    # Optuna objective\n",
    "    def objective(trial):\n",
    "        params = base_params.copy()\n",
    "        params['max_depth'] = trial.suggest_int('max_depth', 4, 10)\n",
    "        params['learning_rate'] = trial.suggest_float('learning_rate', 0.01, 0.1, log=True)\n",
    "        params['subsample'] = trial.suggest_float('subsample', 0.5, 0.9)\n",
    "        params['colsample_bytree'] = trial.suggest_float('colsample_bytree', 0.3, 0.9)\n",
    "        params['min_child_weight'] = trial.suggest_int('min_child_weight', 1, 20)\n",
    "        params['reg_alpha'] = trial.suggest_float('reg_alpha', 1e-3, 10, log=True)\n",
    "        params['reg_lambda'] = trial.suggest_float('reg_lambda', 1e-3, 10, log=True)\n",
    "        n_rounds = trial.suggest_int('n_rounds', 300, 2000)\n",
    "        return eval_oof(params, n_rounds, X_np, y_target)\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=N_TRIALS)\n",
    "\n",
    "    best_p = study.best_params\n",
    "    auc_optuna = study.best_value\n",
    "\n",
    "    # Сохраняем лучшие параметры\n",
    "    best_params_dict[target_col] = {\n",
    "        'max_depth': best_p['max_depth'],\n",
    "        'learning_rate': best_p['learning_rate'],\n",
    "        'n_rounds': best_p['n_rounds'],\n",
    "        'subsample': best_p['subsample'],\n",
    "        'colsample_bytree': best_p['colsample_bytree'],\n",
    "        'min_child_weight': best_p['min_child_weight'],\n",
    "        'reg_alpha': best_p['reg_alpha'],\n",
    "        'reg_lambda': best_p['reg_lambda'],\n",
    "        'best_auc': auc_optuna,\n",
    "        'default_auc': auc_default,\n",
    "    }\n",
    "\n",
    "    # Чекпоинт после каждого таргета\n",
    "    with open(CHECKPOINT, 'w') as f:\n",
    "        json.dump(best_params_dict, f, indent=2)\n",
    "\n",
    "    elapsed = (time.time() - start_t) / 60\n",
    "    delta = auc_optuna - auc_default\n",
    "    print(f\"[{t_idx+1:2d}/41] {target_col:<15} {auc_default:.4f}    {auc_optuna:.4f}    {delta:+.4f}    {elapsed:.1f}м  \"\n",
    "          f\"d={best_p['max_depth']} lr={best_p['learning_rate']:.3f} r={best_p['n_rounds']} \"\n",
    "          f\"col={best_p['colsample_bytree']:.2f} mcw={best_p['min_child_weight']}\")\n",
    "\n",
    "elapsed_total = (time.time() - start_total) / 60\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Готово! Время: {elapsed_total:.1f} мин\")\n",
    "print(f\"Параметры сохранены: {CHECKPOINT}\")\n",
    "\n",
    "# Итоговая статистика\n",
    "defaults = [v['default_auc'] for v in best_params_dict.values() if 'default_auc' in v]\n",
    "optimized = [v['best_auc'] for v in best_params_dict.values()]\n",
    "print(f\"Средний Default AUC: {np.mean(defaults):.4f}\")\n",
    "print(f\"Средний Optuna AUC:  {np.mean(optimized):.4f}\")\n",
    "print(f\"Средний прирост:     {np.mean(optimized) - np.mean(defaults):+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Шаг 2: L1 OOF генерация (750k, 5-fold, Optuna params + Feature Selection)\n",
    "\n",
    "Для каждого таргета:\n",
    "1. Черновик: обучаем XGBoost на 100 iter → feature importance → отбираем топ-95% cumulative gain\n",
    "2. Чистовик: 5-fold OOF с Optuna параметрами на отобранных фичах\n",
    "\n",
    "**Время: ~135 мин на A100.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import json, time, gc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "DATA = '/content/drive/MyDrive/data_fusion'\n",
    "\n",
    "# === Загрузка данных ===\n",
    "print(\"Загрузка данных...\")\n",
    "train_main = pd.read_parquet(f'{DATA}/train_main_features.parquet')\n",
    "train_extra = pd.read_parquet(f'{DATA}/train_extra_features.parquet')\n",
    "train_target = pd.read_parquet(f'{DATA}/train_target.parquet')\n",
    "\n",
    "X_train_df = train_main.merge(train_extra, on='customer_id', how='left').drop(columns=['customer_id'])\n",
    "y_train_np = train_target.drop(columns=['customer_id']).values\n",
    "target_columns = train_target.drop(columns=['customer_id']).columns.tolist()\n",
    "feature_columns = X_train_df.columns.tolist()\n",
    "\n",
    "X_train_np = np.ascontiguousarray(X_train_df.astype(np.float32).values)\n",
    "del train_main, train_extra, train_target, X_train_df; gc.collect()\n",
    "\n",
    "# === Загрузка Optuna параметров ===\n",
    "with open(f'{DATA}/optuna_best_params.json', 'r') as f:\n",
    "    optuna_params = json.load(f)\n",
    "print(f\"Optuna параметры: {len(optuna_params)} таргетов\")\n",
    "\n",
    "# === Настройки OOF ===\n",
    "N_FOLDS = 5\n",
    "N_ROUNDS_DRAFT = 100      # Итераций для черновика (feature selection)\n",
    "GAIN_THRESHOLD = 0.95     # Порог cumulative gain\n",
    "OOF_PATH = f'{DATA}/xgb_oof_optuna.npy'\n",
    "FEAT_PATH = f'{DATA}/xgb_best_features_optuna.json'\n",
    "\n",
    "oof_predictions = np.zeros_like(y_train_np, dtype=np.float32)\n",
    "best_features_dict = {}\n",
    "\n",
    "# Мастер-матрица для черновиков (QuantileDMatrix — быстрее для повторных обучений)\n",
    "print(\"Построение мастер-матрицы...\")\n",
    "dtrain_full_draft = xgb.QuantileDMatrix(X_train_np)\n",
    "print(f\"Данные: {X_train_np.shape}, старт OOF...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_total = time.time()\n",
    "\n",
    "for t_idx, target_col in enumerate(target_columns):\n",
    "    start_t = time.time()\n",
    "    y_target = y_train_np[:, t_idx]\n",
    "    n_pos = int(y_target.sum())\n",
    "\n",
    "    # Загружаем Optuna параметры для этого таргета\n",
    "    p = optuna_params.get(target_col, {})\n",
    "\n",
    "    current_params = {\n",
    "        'objective': 'binary:logistic', 'eval_metric': 'auc',\n",
    "        'tree_method': 'hist', 'device': 'cuda', 'seed': 42, 'verbosity': 0,\n",
    "        'max_depth': int(p.get('max_depth', 6)),\n",
    "        'learning_rate': p.get('learning_rate', 0.05),\n",
    "        'subsample': p.get('subsample', 0.8),\n",
    "        'colsample_bytree': p.get('colsample_bytree', 0.8),\n",
    "        'min_child_weight': int(p.get('min_child_weight', 5)),\n",
    "        'reg_alpha': p.get('reg_alpha', 0.01),\n",
    "        'reg_lambda': p.get('reg_lambda', 1.0),\n",
    "    }\n",
    "    n_rounds = int(p.get('n_rounds', 500))\n",
    "\n",
    "    # Защита: слишком мало позитивов\n",
    "    current_folds = min(N_FOLDS, n_pos) if n_pos > 0 else 0\n",
    "    if current_folds < 2:\n",
    "        oof_predictions[:, t_idx] = 0.0001\n",
    "        best_features_dict[target_col] = feature_columns\n",
    "        print(f\"[{t_idx+1:2d}/41] {target_col:<15} ПРОПУСК (pos={n_pos})\")\n",
    "        continue\n",
    "\n",
    "    # --- Черновик: feature selection (cumulative gain 95%) ---\n",
    "    dtrain_full_draft.set_label(y_target)\n",
    "    draft_params = current_params.copy()\n",
    "    model_draft = xgb.train(draft_params, dtrain_full_draft,\n",
    "                            num_boost_round=N_ROUNDS_DRAFT, verbose_eval=False)\n",
    "\n",
    "    imp = model_draft.get_score(importance_type='gain')\n",
    "    imp_sorted = sorted(imp.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    if not imp_sorted:\n",
    "        selected_indices = list(range(X_train_np.shape[1]))\n",
    "    else:\n",
    "        selected_indices = []\n",
    "        total_gain = sum(v for _, v in imp_sorted)\n",
    "        cum_gain = 0\n",
    "        for feat, gain in imp_sorted:\n",
    "            cum_gain += gain\n",
    "            selected_indices.append(int(feat[1:]))  # 'f123' -> 123\n",
    "            if cum_gain / total_gain >= GAIN_THRESHOLD:\n",
    "                break\n",
    "        if len(selected_indices) < 10:\n",
    "            selected_indices = [int(f[1:]) for f, _ in imp_sorted[:10]]\n",
    "\n",
    "    best_features_dict[target_col] = [feature_columns[i] for i in selected_indices]\n",
    "\n",
    "    # --- Чистовик: K-Fold OOF на отобранных фичах с Optuna параметрами ---\n",
    "    X_target = X_train_np[:, selected_indices].copy(order='C')\n",
    "    skf = StratifiedKFold(n_splits=current_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_target, y_target):\n",
    "        dtrain = xgb.QuantileDMatrix(X_target[train_idx], label=y_target[train_idx])\n",
    "        dval = xgb.QuantileDMatrix(X_target[val_idx], label=y_target[val_idx], ref=dtrain)\n",
    "        model = xgb.train(current_params, dtrain,\n",
    "                          num_boost_round=n_rounds, verbose_eval=False)\n",
    "        oof_predictions[val_idx, t_idx] = model.predict(dval)\n",
    "\n",
    "    try:\n",
    "        auc = roc_auc_score(y_target, oof_predictions[:, t_idx])\n",
    "    except:\n",
    "        auc = 0.5\n",
    "\n",
    "    elapsed = (time.time() - start_t) / 60\n",
    "    print(f\"[{t_idx+1:2d}/41] {target_col:<15} OOF AUC: {auc:.4f} | \"\n",
    "          f\"Фичей: {len(selected_indices):<4} | {elapsed:.1f} мин\")\n",
    "\n",
    "    # Чекпоинт каждые 5 таргетов\n",
    "    if (t_idx + 1) % 5 == 0:\n",
    "        np.save(OOF_PATH, oof_predictions)\n",
    "        with open(FEAT_PATH, 'w') as f:\n",
    "            json.dump(best_features_dict, f)\n",
    "\n",
    "# === Итоги ===\n",
    "elapsed_total = (time.time() - start_total) / 60\n",
    "oof_aucs = []\n",
    "for i, col in enumerate(target_columns):\n",
    "    try:\n",
    "        oof_aucs.append(roc_auc_score(y_train_np[:, i], oof_predictions[:, i]))\n",
    "    except:\n",
    "        oof_aucs.append(0.5)\n",
    "\n",
    "print(f\"\\nГотово! Время: {elapsed_total:.1f} мин\")\n",
    "print(f\"OOF Macro AUC: {np.mean(oof_aucs):.4f} (было 0.8352 в EXP-009)\")\n",
    "\n",
    "np.save(OOF_PATH, oof_predictions)\n",
    "with open(FEAT_PATH, 'w') as f:\n",
    "    json.dump(best_features_dict, f)\n",
    "print(f\"Сохранено: {OOF_PATH}, {FEAT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Шаг 3: Full Train + Test Inference (750k → 250k)\n",
    "\n",
    "Обучаем XGBoost на полных 750k (без CV) с Optuna params + отобранными фичами.\n",
    "n_rounds = Optuna n_rounds × 1.2 (больше данных → можно чуть больше итераций).\n",
    "\n",
    "**Время: ~22 мин на A100.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import time\n",
    "\n",
    "# === Загрузка данных ===\n",
    "train_main = pd.read_parquet(f'{DATA}/train_main_features.parquet')\n",
    "train_extra = pd.read_parquet(f'{DATA}/train_extra_features.parquet')\n",
    "test_main = pd.read_parquet(f'{DATA}/test_main_features.parquet')\n",
    "test_extra = pd.read_parquet(f'{DATA}/test_extra_features.parquet')\n",
    "targets = pd.read_parquet(f'{DATA}/train_target.parquet')\n",
    "\n",
    "train = train_main.merge(train_extra, on='customer_id')\n",
    "test = test_main.merge(test_extra, on='customer_id')\n",
    "\n",
    "target_cols = [c for c in targets.columns if c.startswith('target_')]\n",
    "feature_cols = [c for c in train.columns if c != 'customer_id']\n",
    "\n",
    "X_train = train[feature_cols]\n",
    "X_test = test[feature_cols]\n",
    "\n",
    "# Загружаем Optuna params и отобранные фичи\n",
    "with open(f'{DATA}/optuna_best_params.json', 'r') as f:\n",
    "    optuna_params = json.load(f)\n",
    "with open(f'{DATA}/xgb_best_features_optuna.json', 'r') as f:\n",
    "    best_features = json.load(f)\n",
    "\n",
    "print(f\"Таргетов: {len(target_cols)}, Optuna params: {len(optuna_params)}, Feature sets: {len(best_features)}\")\n",
    "\n",
    "# === Full train + predict test ===\n",
    "test_preds = np.zeros((len(X_test), len(target_cols)))\n",
    "start = time.time()\n",
    "\n",
    "for i, col in enumerate(target_cols):\n",
    "    t0 = time.time()\n",
    "    y = targets[col].values\n",
    "\n",
    "    # Фичи для этого таргета\n",
    "    feats = best_features.get(col, feature_cols)\n",
    "\n",
    "    # Optuna params\n",
    "    if col in optuna_params:\n",
    "        p = optuna_params[col]\n",
    "        params = {\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'auc',\n",
    "            'tree_method': 'hist',\n",
    "            'device': 'cuda',\n",
    "            'max_depth': p.get('max_depth', 6),\n",
    "            'learning_rate': p.get('learning_rate', 0.05),\n",
    "            'colsample_bytree': p.get('colsample_bytree', 0.8),\n",
    "            'min_child_weight': p.get('min_child_weight', 5),\n",
    "            'reg_alpha': p.get('reg_alpha', 0),\n",
    "            'reg_lambda': p.get('reg_lambda', 1),\n",
    "            'subsample': 0.8,\n",
    "            'verbosity': 0,\n",
    "        }\n",
    "        n_rounds = p.get('n_rounds', 500)\n",
    "    else:\n",
    "        params = {\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'auc',\n",
    "            'tree_method': 'hist',\n",
    "            'device': 'cuda',\n",
    "            'max_depth': 6,\n",
    "            'learning_rate': 0.05,\n",
    "            'min_child_weight': 5,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'verbosity': 0,\n",
    "        }\n",
    "        n_rounds = 500\n",
    "\n",
    "    # Full train (750k) — без early stopping, +20% итераций\n",
    "    n_rounds_full = int(n_rounds * 1.2)\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train[feats], label=y)\n",
    "    dtest = xgb.DMatrix(X_test[feats])\n",
    "\n",
    "    model = xgb.train(params, dtrain, num_boost_round=n_rounds_full)\n",
    "    test_preds[:, i] = model.predict(dtest)\n",
    "\n",
    "    elapsed = time.time() - t0\n",
    "    if elapsed > 60:\n",
    "        print(f\"[{i+1:2d}/41] {col:20s} n_rounds={n_rounds_full:4d} | Фичей: {len(feats):4d} | {elapsed/60:.1f} мин\")\n",
    "    else:\n",
    "        print(f\"[{i+1:2d}/41] {col:20s} n_rounds={n_rounds_full:4d} | Фичей: {len(feats):4d} | {elapsed:.0f} сек\")\n",
    "\n",
    "    # Checkpoint каждые 10 таргетов\n",
    "    if (i + 1) % 10 == 0:\n",
    "        np.save(f'{DATA}/xgb_test_optuna_checkpoint.npy', test_preds)\n",
    "\n",
    "np.save(f'{DATA}/xgb_test_optuna.npy', test_preds)\n",
    "total = (time.time() - start) / 60\n",
    "print(f\"\\nГотово! Время: {total:.1f} мин\")\n",
    "print(f\"Сохранено: xgb_test_optuna.npy ({test_preds.shape})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Шаг 4: L2 Стекинг + Сабмит\n",
    "\n",
    "Мета-модель XGBoost (depth=2, 100 iter) на 41 OOF-фиче.\n",
    "L2 учит корреляции между таргетами (группы продуктов, антагонист target_10_1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# === Загрузка ===\n",
    "oof = np.load(f'{DATA}/xgb_oof_optuna.npy')        # (750k, 41)\n",
    "test_preds = np.load(f'{DATA}/xgb_test_optuna.npy') # (250k, 41)\n",
    "targets = pd.read_parquet(f'{DATA}/train_target.parquet')\n",
    "test_main = pd.read_parquet(f'{DATA}/test_main_features.parquet')\n",
    "\n",
    "target_cols = [c for c in targets.columns if c.startswith('target_')]\n",
    "y_true = targets[target_cols].values\n",
    "\n",
    "print(f\"OOF: {oof.shape}, Test: {test_preds.shape}, Targets: {y_true.shape}\")\n",
    "print(f\"L1 OOF Macro AUC: {roc_auc_score(y_true, oof, average='macro'):.6f}\")\n",
    "\n",
    "# === L2 мета-модель ===\n",
    "meta_oof = np.zeros_like(oof)\n",
    "meta_test = np.zeros_like(test_preds)\n",
    "\n",
    "l2_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'tree_method': 'hist',\n",
    "    'device': 'cuda',\n",
    "    'max_depth': 2,\n",
    "    'learning_rate': 0.05,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'verbosity': 0,\n",
    "}\n",
    "\n",
    "for i, col in enumerate(target_cols):\n",
    "    y = y_true[:, i]\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_fold_preds = []\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(skf.split(oof, y)):\n",
    "        dtrain = xgb.DMatrix(oof[tr_idx], label=y[tr_idx])\n",
    "        dval = xgb.DMatrix(oof[val_idx], label=y[val_idx])\n",
    "        dtest = xgb.DMatrix(test_preds)\n",
    "\n",
    "        model = xgb.train(\n",
    "            l2_params, dtrain,\n",
    "            num_boost_round=100,\n",
    "            evals=[(dval, 'val')],\n",
    "            early_stopping_rounds=20,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "\n",
    "        meta_oof[val_idx, i] = model.predict(dval)\n",
    "        test_fold_preds.append(model.predict(dtest))\n",
    "\n",
    "    meta_test[:, i] = np.mean(test_fold_preds, axis=0)\n",
    "\n",
    "meta_auc = roc_auc_score(y_true, meta_oof, average='macro')\n",
    "print(f\"\\nL2 Meta OOF Macro AUC: {meta_auc:.6f}\")\n",
    "\n",
    "# === Per-target сравнение ===\n",
    "print(f\"\\n{'Таргет':20s} {'L1 OOF':>8s} {'L2 Meta':>8s} {'Дельта':>8s}\")\n",
    "for i, col in enumerate(target_cols):\n",
    "    l1 = roc_auc_score(y_true[:, i], oof[:, i])\n",
    "    l2 = roc_auc_score(y_true[:, i], meta_oof[:, i])\n",
    "    print(f\"{col:20s} {l1:8.4f} {l2:8.4f} {l2-l1:+8.4f}\")\n",
    "\n",
    "# === Сабмит ===\n",
    "submit = pd.DataFrame({'customer_id': test_main['customer_id'].values.astype(np.int32)})\n",
    "for i, col in enumerate(target_cols):\n",
    "    submit_col = col.replace('target_', 'predict_')\n",
    "    submit[submit_col] = meta_test[:, i].astype(np.float64)\n",
    "\n",
    "submit.to_parquet(f'{DATA}/submission_optuna_stacking.parquet', index=False)\n",
    "print(f\"\\nСабмит: {submit.shape}\")\n",
    "print(f\"Колонки: {submit.columns.tolist()[:3]}...\")\n",
    "print(f\"dtypes: customer_id={submit['customer_id'].dtype}, preds={submit.iloc[:, 1].dtype}\")\n",
    "print(f\"\\n>>> Public LB: 0.8472 <<<\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}