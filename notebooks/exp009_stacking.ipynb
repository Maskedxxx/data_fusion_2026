{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXP-009: Стекинг (OOF + мета-модель)\n",
    "\n",
    "**Результат: Public LB 0.8444** (лучший результат, +0.0032 к EXP-007b)\n",
    "\n",
    "## Архитектура\n",
    "- **Уровень 1 (L1)**: XGBoost 41 модель × 5-fold OOF + per-target feature selection (cumulative gain 95%)\n",
    "- **Уровень 2 (L2)**: XGBoost мета-модель (depth=2) на 41 OOF-фиче → учит корреляции между таргетами\n",
    "\n",
    "## Пайплайн\n",
    "1. Загрузка данных → numpy float32\n",
    "2. Генерация OOF предсказаний (750k × 41) с отбором фичей\n",
    "3. Full train + test inference с отобранными фичами\n",
    "4. Мета-модель на OOF → финальный сабмит\n",
    "\n",
    "## Ключевой инсайт\n",
    "Мета-модель видит связи между таргетами: если клиент покупает продукт A (частый),\n",
    "то продукт B (редкий) тоже вероятен. Слабые таргеты получают сигнал от частых связанных.\n",
    "На быстром тесте (100k): target_5_2 +0.081, target_2_5 +0.071."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 1: Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import gc\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# === ПУТИ ===\n",
    "# Для Spark:\n",
    "DATA = '/home/masked/projects/data_fusion/data/raw'\n",
    "# Для Colab:\n",
    "# DATA = '/content/drive/MyDrive/data_fusion'\n",
    "\n",
    "print(\"1. Загрузка обучающей выборки...\")\n",
    "train_main = pd.read_parquet(f'{DATA}/train_main_features.parquet')\n",
    "train_extra = pd.read_parquet(f'{DATA}/train_extra_features.parquet')\n",
    "train_target = pd.read_parquet(f'{DATA}/train_target.parquet')\n",
    "\n",
    "X_train_df = train_main.merge(train_extra, on='customer_id', how='left')\n",
    "X_train_df = X_train_df.drop(columns=['customer_id'])\n",
    "\n",
    "y_train_df = train_target.drop(columns=['customer_id'])\n",
    "target_columns = y_train_df.columns.tolist()\n",
    "\n",
    "print(\"2. Загрузка тестовой выборки...\")\n",
    "test_main = pd.read_parquet(f'{DATA}/test_main_features.parquet')\n",
    "test_extra = pd.read_parquet(f'{DATA}/test_extra_features.parquet')\n",
    "\n",
    "X_test_df = test_main.merge(test_extra, on='customer_id', how='left')\n",
    "test_customer_ids = test_main['customer_id'].values  # Для сабмита\n",
    "X_test_df = X_test_df.drop(columns=['customer_id'])\n",
    "\n",
    "feature_columns = X_train_df.columns.tolist()\n",
    "\n",
    "print(\"3. Конвертация в numpy.float32 (для GPU)...\")\n",
    "start = time.time()\n",
    "\n",
    "X_train_np = X_train_df.astype(np.float32).values\n",
    "y_train_np = y_train_df.values\n",
    "X_test_np = X_test_df.astype(np.float32).values\n",
    "\n",
    "print(f\"Конвертация завершена за {time.time() - start:.1f} сек.\")\n",
    "print(f\"X_train: {X_train_np.shape} | X_test: {X_test_np.shape} | y_train: {y_train_np.shape}\")\n",
    "\n",
    "del train_main, train_extra, train_target, test_main, test_extra\n",
    "del X_train_df, y_train_df, X_test_df\n",
    "gc.collect()\n",
    "print(\"Готово!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 2: Уровень 1 — Генерация OOF предсказаний\n",
    "\n",
    "Для каждого из 41 таргета:\n",
    "1. **Черновик** (100 iter на всех фичах) → извлекаем feature importance → отбираем топ-95% cumulative gain\n",
    "2. **Чистовик** (500 iter на отобранных фичах) → 5-fold StratifiedKFold → OOF предсказания\n",
    "\n",
    "Результат: матрица `xgb_oof_train.npy` (750000, 41) — честные предсказания для каждого клиента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "N_FOLDS = 5\n",
    "N_ROUNDS_DRAFT = 100   # Черновик для отбора фичей\n",
    "N_ROUNDS_FINAL = 500   # Чистовик для OOF\n",
    "GAIN_THRESHOLD = 0.95  # Порог cumulative gain\n",
    "\n",
    "base_params = {\n",
    "    'objective': 'binary:logistic', 'eval_metric': 'auc',\n",
    "    'learning_rate': 0.05, 'max_depth': 6,\n",
    "    'subsample': 0.8, 'colsample_bytree': 0.8,\n",
    "    'tree_method': 'hist', 'device': 'cuda', 'seed': 42, 'verbosity': 0,\n",
    "}\n",
    "\n",
    "oof_predictions = np.zeros_like(y_train_np, dtype=np.float32)\n",
    "oof_aucs = []\n",
    "best_features_dict = {}\n",
    "\n",
    "# Мастер-матрица для быстрых черновиков (строится один раз)\n",
    "print(\"Выравнивание памяти (ascontiguousarray)...\")\n",
    "X_train_np = np.ascontiguousarray(X_train_np)\n",
    "\n",
    "print(\"Построение мастер-матрицы для черновиков (1-2 мин)...\")\n",
    "dtrain_full_draft = xgb.QuantileDMatrix(X_train_np)\n",
    "print(\"Мастер-матрица готова!\")\n",
    "\n",
    "print(f\"Начинаем OOF цикл для {len(target_columns)} таргетов...\")\n",
    "start_total = time.time()\n",
    "\n",
    "for t_idx, target_col in enumerate(target_columns):\n",
    "    start_target = time.time()\n",
    "    y_target = y_train_np[:, t_idx]\n",
    "    n_pos = int(y_target.sum())\n",
    "\n",
    "    # Защита: если позитивов меньше фолдов — пропускаем\n",
    "    current_folds = min(N_FOLDS, n_pos) if n_pos > 0 else 0\n",
    "    if current_folds < 2:\n",
    "        print(f\"[{t_idx+1:2d}/41] {target_col:<15} ПРОПУСК (pos: {n_pos})\")\n",
    "        oof_predictions[:, t_idx] = 0.0001\n",
    "        oof_aucs.append(0.5)\n",
    "        best_features_dict[target_col] = feature_columns\n",
    "        continue\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=current_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Адаптивный min_child_weight: для редких таргетов разрешаем мелкие сплиты\n",
    "    current_min_child = 5 if n_pos > 500 else 1\n",
    "    current_params = base_params.copy()\n",
    "    current_params['min_child_weight'] = current_min_child\n",
    "\n",
    "    # --- ШАГ 1: Черновик → отбор фичей по cumulative gain 95% ---\n",
    "    dtrain_full_draft.set_label(y_target)\n",
    "    model_draft = xgb.train(current_params, dtrain_full_draft,\n",
    "                            num_boost_round=N_ROUNDS_DRAFT, verbose_eval=False)\n",
    "\n",
    "    imp = model_draft.get_score(importance_type='gain')\n",
    "    imp_sorted = sorted(imp.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    selected_indices = []\n",
    "    if not imp_sorted:\n",
    "        selected_indices = list(range(X_train_np.shape[1]))\n",
    "    else:\n",
    "        total_gain = sum(v for _, v in imp_sorted)\n",
    "        cum_gain = 0\n",
    "        for feat, gain in imp_sorted:\n",
    "            cum_gain += gain\n",
    "            feat_idx = int(feat[1:])  # 'f123' -> 123\n",
    "            selected_indices.append(feat_idx)\n",
    "            if cum_gain / total_gain >= GAIN_THRESHOLD:\n",
    "                break\n",
    "\n",
    "        if len(selected_indices) < 10:\n",
    "            selected_indices = [int(f[1:]) for f, _ in imp_sorted[:10]]\n",
    "\n",
    "    best_features_dict[target_col] = [feature_columns[i] for i in selected_indices]\n",
    "\n",
    "    # --- ШАГ 2: Чистовик — K-Fold OOF на отобранных фичах ---\n",
    "    X_target_np = X_train_np[:, selected_indices].copy(order='C')\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_target_np, y_target):\n",
    "        dtrain = xgb.QuantileDMatrix(X_target_np[train_idx], label=y_target[train_idx])\n",
    "        dval = xgb.QuantileDMatrix(X_target_np[val_idx], label=y_target[val_idx], ref=dtrain)\n",
    "\n",
    "        model = xgb.train(current_params, dtrain,\n",
    "                          num_boost_round=N_ROUNDS_FINAL, verbose_eval=False)\n",
    "        oof_predictions[val_idx, t_idx] = model.predict(dval)\n",
    "\n",
    "    # Итоги таргета\n",
    "    try:\n",
    "        auc = roc_auc_score(y_target, oof_predictions[:, t_idx])\n",
    "    except ValueError:\n",
    "        auc = 0.5\n",
    "\n",
    "    oof_aucs.append(auc)\n",
    "    elapsed_target = (time.time() - start_target) / 60\n",
    "    print(f\"[{t_idx+1:2d}/41] {target_col:<15} OOF AUC: {auc:.4f} | pos: {n_pos:<6} | \"\n",
    "          f\"Фичей: {len(selected_indices):<4} | {elapsed_target:.1f} мин\")\n",
    "\n",
    "    # Чекпоинт каждые 5 таргетов\n",
    "    if (t_idx + 1) % 5 == 0:\n",
    "        np.save(f'{DATA}/xgb_oof_checkpoint.npy', oof_predictions)\n",
    "        with open(f'{DATA}/xgb_best_features_checkpoint.json', 'w') as f:\n",
    "            json.dump(best_features_dict, f)\n",
    "\n",
    "# === Итоги ===\n",
    "elapsed_total = (time.time() - start_total) / 60\n",
    "print(f\"\\nГотово! Общее время: {elapsed_total:.1f} мин\")\n",
    "print(f\"Базовый OOF Macro AUC (XGBoost): {np.mean(oof_aucs):.4f}\")\n",
    "\n",
    "np.save(f'{DATA}/xgb_oof_train.npy', oof_predictions)\n",
    "with open(f'{DATA}/xgb_best_features.json', 'w') as f:\n",
    "    json.dump(best_features_dict, f)\n",
    "print(\"OOF-матрица и словарь фичей сохранены!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 3: Full Train + Test Inference\n",
    "\n",
    "Обучаем XGBoost на **всех** 750k для каждого таргета с отобранными фичами,\n",
    "предсказываем на test (250k).\n",
    "\n",
    "Результат: `xgb_test_preds.npy` (250000, 41) — базовые предсказания уровня L1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ROUNDS_FINAL = 500\n",
    "\n",
    "# Загружаем отобранные фичи (если ядро перезапускалось)\n",
    "with open(f'{DATA}/xgb_best_features.json', 'r') as f:\n",
    "    best_features_dict = json.load(f)\n",
    "\n",
    "# Выравниваем память для test\n",
    "print(\"Выравнивание памяти...\")\n",
    "X_train_np = np.ascontiguousarray(X_train_np)\n",
    "X_test_np = np.ascontiguousarray(X_test_np)\n",
    "\n",
    "test_predictions = np.zeros((X_test_np.shape[0], len(target_columns)), dtype=np.float32)\n",
    "\n",
    "print(f\"Начинаем обучение и inference для {len(target_columns)} таргетов...\")\n",
    "start_total = time.time()\n",
    "\n",
    "for t_idx, target_col in enumerate(target_columns):\n",
    "    start_target = time.time()\n",
    "    y_target = y_train_np[:, t_idx]\n",
    "    n_pos = int(y_target.sum())\n",
    "\n",
    "    if n_pos < 2:\n",
    "        print(f\"[{t_idx+1:2d}/41] {target_col:<15} ПРОПУСК (pos: {n_pos})\")\n",
    "        test_predictions[:, t_idx] = 0.0001\n",
    "        continue\n",
    "\n",
    "    current_min_child = 5 if n_pos > 500 else 1\n",
    "    current_params = base_params.copy()\n",
    "    current_params['min_child_weight'] = current_min_child\n",
    "\n",
    "    # Индексы отобранных фичей\n",
    "    selected_feature_names = best_features_dict[target_col]\n",
    "    selected_indices = [feature_columns.index(name) for name in selected_feature_names]\n",
    "\n",
    "    # C-contiguous срезы для скорости\n",
    "    X_train_target = X_train_np[:, selected_indices].copy(order='C')\n",
    "    X_test_target = X_test_np[:, selected_indices].copy(order='C')\n",
    "\n",
    "    dtrain = xgb.QuantileDMatrix(X_train_target, label=y_target)\n",
    "    dtest = xgb.QuantileDMatrix(X_test_target, ref=dtrain)\n",
    "\n",
    "    model = xgb.train(current_params, dtrain,\n",
    "                      num_boost_round=N_ROUNDS_FINAL, verbose_eval=False)\n",
    "    test_predictions[:, t_idx] = model.predict(dtest)\n",
    "\n",
    "    elapsed_target = (time.time() - start_target) / 60\n",
    "    if (t_idx + 1) % 5 == 0 or t_idx == 0:\n",
    "        print(f\"[{t_idx+1:2d}/41] {target_col:<15} Готово | \"\n",
    "              f\"Фичей: {len(selected_indices):<4} | {elapsed_target:.1f} мин\")\n",
    "\n",
    "elapsed_total = (time.time() - start_total) / 60\n",
    "print(f\"\\nInference завершён! Общее время: {elapsed_total:.1f} мин\")\n",
    "\n",
    "np.save(f'{DATA}/xgb_test_preds.npy', test_predictions)\n",
    "print(\"Тестовые предсказания сохранены!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 4: Уровень 2 — Мета-модель (Стекинг)\n",
    "\n",
    "Мета-модель (XGBoost depth=2) обучается предсказывать каждый таргет\n",
    "на основе **41 OOF-предсказания**. Она учит корреляции:\n",
    "- Группы 3-7 коррелируют (пакетные покупки)\n",
    "- target_10_1 — антагонист (отрицательная корреляция)\n",
    "- Редкие таргеты получают сигнал от частых связанных\n",
    "\n",
    "Результат: `submission.parquet` — финальный сабмит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем OOF и test предсказания (если ядро перезапускалось)\n",
    "X_meta_train = np.load(f'{DATA}/xgb_oof_train.npy')\n",
    "X_meta_test = np.load(f'{DATA}/xgb_test_preds.npy')\n",
    "\n",
    "# Загружаем таргеты\n",
    "train_target = pd.read_parquet(f'{DATA}/train_target.parquet')\n",
    "y_train = train_target.drop(columns=['customer_id']).values\n",
    "target_columns = train_target.drop(columns=['customer_id']).columns.tolist()\n",
    "\n",
    "# ID клиентов для сабмита\n",
    "test_main = pd.read_parquet(f'{DATA}/test_main_features.parquet')\n",
    "test_customer_ids = test_main['customer_id'].values\n",
    "del train_target, test_main\n",
    "gc.collect()\n",
    "\n",
    "print(f\"OOF train: {X_meta_train.shape} | Test preds: {X_meta_test.shape}\")\n",
    "\n",
    "# Параметры мета-модели: неглубокие деревья, чтобы не переобучиться на 41 фиче\n",
    "meta_params = {\n",
    "    'objective': 'binary:logistic', 'eval_metric': 'auc',\n",
    "    'max_depth': 2, 'learning_rate': 0.05, 'n_estimators': 100,\n",
    "    'tree_method': 'hist', 'device': 'cuda', 'random_state': 42,\n",
    "}\n",
    "\n",
    "final_test_preds = np.zeros_like(X_meta_test)\n",
    "meta_aucs = []\n",
    "\n",
    "print(f\"\\nОбучение мета-модели (L2) для {len(target_columns)} таргетов...\")\n",
    "start = time.time()\n",
    "\n",
    "for i, col in enumerate(target_columns):\n",
    "    clf = xgb.XGBClassifier(**meta_params)\n",
    "    clf.fit(X_meta_train, y_train[:, i])\n",
    "\n",
    "    final_test_preds[:, i] = clf.predict_proba(X_meta_test)[:, 1]\n",
    "\n",
    "    # Train AUC мета-модели (завышен, т.к. не OOF для L2)\n",
    "    oof_meta_preds = clf.predict_proba(X_meta_train)[:, 1]\n",
    "    auc = roc_auc_score(y_train[:, i], oof_meta_preds)\n",
    "    meta_aucs.append(auc)\n",
    "\n",
    "    if (i + 1) % 5 == 0 or i == 0:\n",
    "        print(f\"[{i+1:2d}/41] {col:<15} Meta-AUC: {auc:.4f}\")\n",
    "\n",
    "print(f\"\\nСредний Meta-AUC: {np.mean(meta_aucs):.4f}\")\n",
    "print(f\"Время: {(time.time() - start)/60:.1f} мин\")\n",
    "\n",
    "# === Формирование сабмита ===\n",
    "submission = pd.DataFrame({'customer_id': test_customer_ids})\n",
    "for i, col in enumerate(target_columns):\n",
    "    # predict_ без target_ — формат платформы\n",
    "    col_name = col.replace('target_', '')\n",
    "    submission[f'predict_{col_name}'] = final_test_preds[:, i].astype(np.float64)\n",
    "\n",
    "submission.to_parquet('submission.parquet', index=False)\n",
    "print(f\"\\nСабмит готов! {submission.shape}\")\n",
    "print(submission.head(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}