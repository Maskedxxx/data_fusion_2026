{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "053b3d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c50137a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main features: 199\n",
      "Extra features: 2241\n",
      "Всего: 2440\n",
      "\n",
      "Пропуски в extra features:\n",
      "      0-1%:   12 фичей  █\n",
      "     1-10%:    9 фичей  ▌\n",
      "    10-30%:  774 фичей  █████████████████████████████████████████████████████████████████████████████\n",
      "    30-50%:  322 фичей  ████████████████████████████████\n",
      "    50-70%:  167 фичей  ████████████████▌\n",
      "    70-90%:  386 фичей  ██████████████████████████████████████▌\n",
      "    90-99%:  275 фичей  ███████████████████████████▌\n",
      "   99-100%:  296 фичей  █████████████████████████████▌\n",
      "\n",
      "Без пропусков: 0\n",
      "Пропусков >90%: 571\n"
     ]
    }
   ],
   "source": [
    "import polars as pl                                                                                                                                         \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Загрузка\n",
    "train_main = pl.read_parquet('../data/raw/train_main_features.parquet')\n",
    "train_extra = pl.read_parquet('../data/raw/train_extra_features.parquet')\n",
    "target = pl.read_parquet('../data/raw/train_target.parquet')\n",
    "\n",
    "target_columns = [col for col in target.columns if col.startswith('target')]\n",
    "\n",
    "# Статистика по extra\n",
    "extra_cols = [c for c in train_extra.columns if c != 'customer_id']\n",
    "print(f'Main features: {len(train_main.columns) - 1}')\n",
    "print(f'Extra features: {len(extra_cols)}')\n",
    "print(f'Всего: {len(train_main.columns) - 1 + len(extra_cols)}')\n",
    "\n",
    "# Пропуски в extra\n",
    "null_counts = train_extra.select(extra_cols).null_count()\n",
    "null_pcts = {col: null_counts[col][0] / len(train_extra) * 100 for col in extra_cols}\n",
    "\n",
    "# Распределение пропусков\n",
    "bins = [0, 1, 10, 30, 50, 70, 90, 99, 100]\n",
    "labels = ['0-1%', '1-10%', '10-30%', '30-50%', '50-70%', '70-90%', '90-99%', '99-100%']\n",
    "hist = [0] * len(labels)\n",
    "for pct in null_pcts.values():\n",
    "    for i in range(len(bins) - 1):\n",
    "        if bins[i] <= pct < bins[i+1]:\n",
    "            hist[i] += 1\n",
    "            break\n",
    "\n",
    "print(f'\\nПропуски в extra features:')\n",
    "for label, count in zip(labels, hist):\n",
    "    bar = '█' * (count // 10) + '▌' * (1 if count % 10 >= 5 else 0)\n",
    "    print(f'  {label:>8s}: {count:4d} фичей  {bar}')\n",
    "\n",
    "# Сколько фичей без пропусков\n",
    "no_nulls = sum(1 for p in null_pcts.values() if p == 0)\n",
    "heavy_nulls = sum(1 for p in null_pcts.values() if p > 90)\n",
    "print(f'\\nБез пропусков: {no_nulls}')\n",
    "print(f'Пропусков >90%: {heavy_nulls}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "137e6dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используется: 1318 из 2440 (54%)\n",
      "Не используется: 1122 (46%)\n",
      "\n",
      "0-30% пропусков (795 фичей):\n",
      "  Используется: 393 (49%)\n",
      "\n",
      "30-70% пропусков (489 фичей):\n",
      "  Используется: 281 (57%)\n",
      "\n",
      "70-90% пропусков (386 фичей):\n",
      "  Используется: 314 (81%)\n",
      "\n",
      "90-100% пропусков (571 фичей):\n",
      "  Используется: 212 (37%)\n",
      "\n",
      "Топ-20 по importance:\n",
      "   1. num_feature_22            | gain:     1177.4 | nulls:   0.0% | main\n",
      "   2. num_feature_27            | gain:      223.3 | nulls:   0.0% | main\n",
      "   3. num_feature_62            | gain:      191.8 | nulls:   0.0% | main\n",
      "   4. num_feature_7             | gain:      167.9 | nulls:   0.0% | main\n",
      "   5. num_feature_1847          | gain:      162.6 | nulls:  29.7% | extra\n",
      "   6. num_feature_176           | gain:       76.9 | nulls:  24.1% | extra\n",
      "   7. num_feature_1429          | gain:       67.4 | nulls:  59.6% | extra\n",
      "   8. num_feature_1549          | gain:       60.7 | nulls:  44.9% | extra\n",
      "   9. num_feature_436           | gain:       56.5 | nulls:  44.5% | extra\n",
      "  10. num_feature_1997          | gain:       56.2 | nulls:  29.7% | extra\n",
      "  11. num_feature_1370          | gain:       55.4 | nulls:  52.2% | extra\n",
      "  12. num_feature_770           | gain:       50.7 | nulls:  44.5% | extra\n",
      "  13. num_feature_70            | gain:       47.2 | nulls:   0.0% | main\n",
      "  14. num_feature_879           | gain:       47.0 | nulls:   2.5% | extra\n",
      "  15. num_feature_33            | gain:       42.1 | nulls:   0.0% | main\n",
      "  16. num_feature_1274          | gain:       40.6 | nulls:  29.7% | extra\n",
      "  17. num_feature_433           | gain:       38.1 | nulls:  29.7% | extra\n",
      "  18. num_feature_25            | gain:       37.9 | nulls:   0.0% | main\n",
      "  19. num_feature_87            | gain:       37.1 | nulls:   0.0% | main\n",
      "  20. num_feature_60            | gain:       34.1 | nulls:   0.0% | main\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb                                                                                                                                       \n",
    "                                                                                                                                                              \n",
    "# Объединяем main + extra                                                                                                                                 \n",
    "train_full = train_main.join(train_extra, on='customer_id', how='left')                                                                                     \n",
    "cat_features = [col for col in train_main.columns if col.startswith('cat_feature')]                                                                         \n",
    "train_full = train_full.with_columns(pl.col(cat_features).cast(pl.Int32))                                                                                   \n",
    "feature_columns = [col for col in train_full.columns if col != 'customer_id']\n",
    "\n",
    "# Подвыборка 100k\n",
    "np.random.seed(42)\n",
    "idx = np.random.choice(len(train_full), 100000, replace=False)\n",
    "X_quick = train_full[idx].select(feature_columns).to_pandas()\n",
    "y_quick = target[idx]['target_8_1'].to_pandas()\n",
    "\n",
    "# Быстрое обучение\n",
    "dtrain = xgb.DMatrix(X_quick, label=y_quick)\n",
    "model = xgb.train({\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 6, 'learning_rate': 0.05,\n",
    "    'subsample': 0.8, 'colsample_bytree': 0.8,\n",
    "    'tree_method': 'hist', 'device': 'cuda',\n",
    "    'seed': 42, 'verbosity': 0\n",
    "}, dtrain, num_boost_round=500)\n",
    "\n",
    "# Feature importance (gain — суммарный прирост качества от фичи)\n",
    "importance = model.get_score(importance_type='gain')\n",
    "\n",
    "# Статистика\n",
    "used = len(importance)\n",
    "unused = len(feature_columns) - used\n",
    "print(f'Используется: {used} из {len(feature_columns)} ({used/len(feature_columns)*100:.0f}%)')\n",
    "print(f'Не используется: {unused} ({unused/len(feature_columns)*100:.0f}%)')\n",
    "\n",
    "# Разбивка по группам пропусков\n",
    "used_set = set(importance.keys())\n",
    "for label, lo, hi in [('0-30%', 0, 30), ('30-70%', 30, 70), ('70-90%', 70, 90), ('90-100%', 90, 100)]:\n",
    "    group = [c for c in extra_cols if lo <= null_pcts[c] < hi]\n",
    "    group_used = [c for c in group if c in used_set]\n",
    "    print(f'\\n{label} пропусков ({len(group)} фичей):')\n",
    "    print(f'  Используется: {len(group_used)} ({len(group_used)/max(len(group),1)*100:.0f}%)')\n",
    "\n",
    "# Топ-20 фичей\n",
    "top20 = sorted(importance.items(), key=lambda x: -x[1])[:20]\n",
    "print(f'\\nТоп-20 по importance:')\n",
    "for i, (feat, gain) in enumerate(top20):\n",
    "    null_pct = null_pcts.get(feat, 0)\n",
    "    src = 'main' if feat.startswith(('cat_', 'num_')) and feat in train_main.columns else 'extra'\n",
    "    print(f'  {i+1:2d}. {feat:25s} | gain: {gain:10.1f} | nulls: {null_pct:5.1f}% | {src}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "341d77fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_sample: (100000, 2440), y_sample: (100000, 41)\n",
      "\n",
      "============================================================\n",
      "Обучаем XGBoost на target_8_1 (сильный)\n",
      "  Positives: 10401 (10.4%)\n",
      "  Используемых фичей: 1171\n",
      "\n",
      "============================================================\n",
      "Обучаем XGBoost на target_9_6 (слабый (частый 22.3%))\n",
      "  Positives: 22158 (22.2%)\n",
      "  Используемых фичей: 1424\n",
      "\n",
      "============================================================\n",
      "Обучаем XGBoost на target_3_1 (слабый)\n",
      "  Positives: 9887 (9.9%)\n",
      "  Используемых фичей: 1381\n",
      "\n",
      "============================================================\n",
      "Обучаем XGBoost на target_1_1 (средний)\n",
      "  Positives: 1007 (1.0%)\n",
      "  Используемых фичей: 1031\n",
      "\n",
      "============================================================\n",
      "АНАЛИЗ ПЕРЕСЕЧЕНИЙ\n",
      "============================================================\n",
      "  target_8_1: 1171 фичей\n",
      "  target_9_6: 1424 фичей\n",
      "  target_3_1: 1381 фичей\n",
      "  target_1_1: 1031 фичей\n",
      "\n",
      "Общее ядро (все 4 таргета): 831 фичей\n",
      "Используются хотя бы одной: 1688 фичей\n",
      "Никем не используются: 752 фичей — кандидаты на удаление\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb                                                                                                                                       \n",
    "import numpy as np                                                                                                                                          \n",
    "import pandas as pd                                                                                                                                         \n",
    "                                                                                                                                                            \n",
    "# === Загрузка данных ===                                                                                                                                   \n",
    "DATA = '/home/masked/projects/data_fusion/data/raw'                                                                                                       \n",
    "\n",
    "train_main = pd.read_parquet(f'{DATA}/train_main_features.parquet')\n",
    "train_extra = pd.read_parquet(f'{DATA}/train_extra_features.parquet')\n",
    "train_target = pd.read_parquet(f'{DATA}/train_target.parquet')\n",
    "\n",
    "X_full = train_main.merge(train_extra, on='customer_id', how='left')\n",
    "customer_ids = X_full['customer_id']\n",
    "X_full = X_full.drop(columns=['customer_id'])\n",
    "\n",
    "# Категориальные → Int32\n",
    "cat_cols = [c for c in X_full.columns if c.startswith('cat_feature')]\n",
    "for c in cat_cols:\n",
    "    X_full[c] = X_full[c].astype('Int32')\n",
    "\n",
    "y_full = train_target.drop(columns=['customer_id'])\n",
    "\n",
    "# Подвыборка 100k для быстрого теста\n",
    "np.random.seed(42)\n",
    "idx = np.random.choice(len(X_full), 100_000, replace=False)\n",
    "X_sample = X_full.iloc[idx].reset_index(drop=True)\n",
    "y_sample = y_full.iloc[idx].reset_index(drop=True)\n",
    "\n",
    "print(f\"X_sample: {X_sample.shape}, y_sample: {y_sample.shape}\")\n",
    "\n",
    "# === Importance на 4 таргетах ===\n",
    "targets_to_check = {\n",
    "    'target_8_1': 'сильный',\n",
    "    'target_9_6': 'слабый (частый 22.3%)',\n",
    "    'target_3_1': 'слабый',\n",
    "    'target_1_1': 'средний',\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic', 'eval_metric': 'auc',\n",
    "    'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 5,\n",
    "    'subsample': 0.8, 'colsample_bytree': 0.8,\n",
    "    'tree_method': 'hist', 'device': 'cuda', 'seed': 42, 'verbosity': 0,\n",
    "}\n",
    "\n",
    "all_importances = {}\n",
    "\n",
    "for target_name, desc in targets_to_check.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Обучаем XGBoost на {target_name} ({desc})\")\n",
    "\n",
    "    y_target = y_sample[target_name].values\n",
    "    n_pos = int(y_target.sum())\n",
    "    print(f\"  Positives: {n_pos} ({n_pos/len(y_target)*100:.1f}%)\")\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_sample, label=y_target, enable_categorical=True)\n",
    "    model = xgb.train(params, dtrain, num_boost_round=500, verbose_eval=False)\n",
    "\n",
    "    imp = model.get_score(importance_type='gain')\n",
    "    all_importances[target_name] = set(imp.keys())\n",
    "    print(f\"  Используемых фичей: {len(imp)}\")\n",
    "\n",
    "# === Анализ пересечений ===\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"АНАЛИЗ ПЕРЕСЕЧЕНИЙ\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "for name, feats in all_importances.items():\n",
    "    print(f\"  {name}: {len(feats)} фичей\")\n",
    "\n",
    "core_features = set.intersection(*all_importances.values())\n",
    "print(f\"\\nОбщее ядро (все 4 таргета): {len(core_features)} фичей\")\n",
    "\n",
    "any_used = set.union(*all_importances.values())\n",
    "print(f\"Используются хотя бы одной: {len(any_used)} фичей\")\n",
    "\n",
    "all_features = set(X_sample.columns)\n",
    "never_used = all_features - any_used\n",
    "print(f\"Никем не используются: {len(never_used)} фичей — кандидаты на удаление\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37458004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Все фичи: 2440\n",
      "Без мусора: 1688\n",
      "Удалено: 752\n",
      "\n",
      "Таргет            Все 2440   1688 фичей      Δ AUC\n",
      "--------------------------------------------------\n",
      "target_8_1          0.9825       0.9827 +   0.0003\n",
      "target_9_6          0.6860       0.6841   -0.0019\n",
      "target_3_1          0.6778       0.6777   -0.0000\n",
      "target_1_1          0.8900       0.8835   -0.0064\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 4: A/B тест — все фичи vs без 752 мусорных                                                                                                         \n",
    "from sklearn.model_selection import train_test_split                                                                                                        \n",
    "from sklearn.metrics import roc_auc_score                                                                                                                   \n",
    "                                                                                                                                                            \n",
    "# Сплит 80/20 для честной оценки                                                                                                                            \n",
    "X_tr, X_vl, y_tr, y_vl = train_test_split(                                                                                                                  \n",
    "    X_sample, y_sample, test_size=0.2, random_state=42                                                                                                    \n",
    ")\n",
    "\n",
    "# Список фичей без 752 мусорных\n",
    "clean_features = sorted(list(any_used))  # 1688 фичей\n",
    "print(f\"Все фичи: {X_tr.shape[1]}\")\n",
    "print(f\"Без мусора: {len(clean_features)}\")\n",
    "print(f\"Удалено: {X_tr.shape[1] - len(clean_features)}\")\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic', 'eval_metric': 'auc',\n",
    "    'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 5,\n",
    "    'subsample': 0.8, 'colsample_bytree': 0.8,\n",
    "    'tree_method': 'hist', 'device': 'cuda', 'seed': 42, 'verbosity': 0,\n",
    "}\n",
    "\n",
    "targets = ['target_8_1', 'target_9_6', 'target_3_1', 'target_1_1']\n",
    "\n",
    "print(f\"\\n{'Таргет':<15} {'Все 2440':>10} {'1688 фичей':>12} {'Δ AUC':>10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for target in targets:\n",
    "    y_t = y_tr[target].values\n",
    "    y_v = y_vl[target].values\n",
    "\n",
    "    # Все фичи\n",
    "    dtrain_all = xgb.DMatrix(X_tr, label=y_t, enable_categorical=True)\n",
    "    dval_all = xgb.DMatrix(X_vl, label=y_v, enable_categorical=True)\n",
    "    model_all = xgb.train(params, dtrain_all, num_boost_round=500, verbose_eval=False)\n",
    "    auc_all = roc_auc_score(y_v, model_all.predict(dval_all))\n",
    "\n",
    "    # Без мусора\n",
    "    dtrain_clean = xgb.DMatrix(X_tr[clean_features], label=y_t, enable_categorical=True)\n",
    "    dval_clean = xgb.DMatrix(X_vl[clean_features], label=y_v, enable_categorical=True)\n",
    "    model_clean = xgb.train(params, dtrain_clean, num_boost_round=500, verbose_eval=False)\n",
    "    auc_clean = roc_auc_score(y_v, model_clean.predict(dval_clean))\n",
    "\n",
    "    delta = auc_clean - auc_all\n",
    "    sign = \"+\" if delta >= 0 else \"\"\n",
    "    print(f\"{target:<15} {auc_all:>10.4f} {auc_clean:>12.4f} {sign}{delta:>9.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73642800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Таргет            n_pos   Все 2440   CumGain95   N фичей    Δ AUC\n",
      "-----------------------------------------------------------------\n",
      "target_2_2         2006     0.9311      0.9335       979 + 0.0024\n",
      "target_8_1         8321     0.9804      0.9807       970 + 0.0002\n",
      "target_1_1          806     0.8729      0.8714       812 -0.0015\n",
      "target_7_2         2184     0.8172      0.8199      1003 + 0.0027\n",
      "target_9_6        17726     0.6735      0.6772      1282 + 0.0036\n",
      "target_3_1         7910     0.6786      0.6788      1239 + 0.0001\n",
      "target_2_8            9     0.9997      0.9997        84 -0.0000\n",
      "target_6_5           40     0.9153      0.8927       334 -0.0227\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mПри выполнении кода в текущей ячейке или предыдущей ячейке ядро аварийно завершило работу. \n",
      "\u001b[1;31mПроверьте код в ячейках, чтобы определить возможную причину сбоя. \n",
      "\u001b[1;31mЩелкните <a href='https://aka.ms/vscodeJupyterKernelCrash'>здесь</a>, чтобы получить дополнительные сведения. \n",
      "\u001b[1;31mПодробнее см. в <a href='command:jupyter.viewOutput'>журнале Jupyter</a>."
     ]
    }
   ],
   "source": [
    "# Ячейка 5: Per-target feature selection через Cumulative Gain (Исправленная)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "\n",
    "# Отключаем ворнинги от pandas при срезах\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 8 репрезентативных таргетов\n",
    "targets = [\n",
    "    'target_2_2', 'target_8_1',   # сильные\n",
    "    'target_1_1', 'target_7_2',   # средние\n",
    "    'target_9_6', 'target_3_1',   # слабые\n",
    "    'target_2_8', 'target_6_5',   # редкие\n",
    "]\n",
    "\n",
    "GAIN_THRESHOLD = 0.95  # оставляем фичи дающие 95% суммарного gain\n",
    "\n",
    "print(f\"{'Таргет':<15} {'n_pos':>7} {'Все 2440':>10} {'CumGain95':>11} {'N фичей':>9} {'Δ AUC':>8}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for target in targets:\n",
    "    # 1. Стратифицированный сплит ДЛЯ КОНКРЕТНОГО ТАРГЕТА!\n",
    "    # Это гарантирует, что редкие единички попадут и в трейн, и в валидацию\n",
    "    X_tr, X_vl, y_tr, y_vl = train_test_split(\n",
    "        X_sample, y_sample[target], test_size=0.2, random_state=42, stratify=y_sample[target]\n",
    "    )\n",
    "    \n",
    "    y_t = y_tr.values\n",
    "    y_v = y_vl.values\n",
    "    n_pos = int(y_t.sum())\n",
    "\n",
    "    # 2. Динамический min_child_weight под редкость таргета\n",
    "    # Если мало позитивов, разрешаем дереву делать сплиты на единичных примерах\n",
    "    current_min_child = 5 if n_pos > 500 else 1\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'binary:logistic', 'eval_metric': 'auc',\n",
    "        'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': current_min_child,\n",
    "        'subsample': 0.8, 'colsample_bytree': 0.8,\n",
    "        'tree_method': 'hist', 'device': 'cuda', 'seed': 42, 'verbosity': 0,\n",
    "    }\n",
    "\n",
    "    # 3. Базовая модель на всех фичах\n",
    "    dtrain = xgb.DMatrix(X_tr, label=y_t, enable_categorical=True)\n",
    "    dval = xgb.DMatrix(X_vl, label=y_v, enable_categorical=True)\n",
    "    model = xgb.train(params, dtrain, num_boost_round=500, verbose_eval=False)\n",
    "    \n",
    "    # Защита от метрики на пустом валидационном сете (для ультра-редких)\n",
    "    try:\n",
    "        auc_all = roc_auc_score(y_v, model.predict(dval))\n",
    "    except ValueError:\n",
    "        auc_all = 0.5 \n",
    "\n",
    "    # 4. Извлекаем importance, сортируем по gain\n",
    "    imp = model.get_score(importance_type='gain')\n",
    "    imp_sorted = sorted(imp.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # 5. ЗАЩИТА ОТ КРАША: Если модель не смогла сделать сплиты (пустой importance)\n",
    "    if not imp_sorted:\n",
    "        print(f\"{target:<15} {n_pos:>7} {auc_all:>10.4f} {'FAIL':>11} {'ALL':>9}  Дерево не строится\")\n",
    "        continue\n",
    "\n",
    "    # 6. Cumulative gain — находим порог 95%\n",
    "    total_gain = sum(v for _, v in imp_sorted)\n",
    "    cum_gain = 0\n",
    "    selected_features = []\n",
    "    \n",
    "    for feat, gain in imp_sorted:\n",
    "        cum_gain += gain\n",
    "        selected_features.append(feat)\n",
    "        if cum_gain / total_gain >= GAIN_THRESHOLD:\n",
    "            break\n",
    "            \n",
    "    # Минимальная защита: оставляем хотя бы 10 фичей, даже если порог пройден раньше\n",
    "    if len(selected_features) < 10:\n",
    "        selected_features = [f for f, _ in imp_sorted[:10]]\n",
    "\n",
    "    # 7. Обучаем на отобранных фичах\n",
    "    dtrain_sel = xgb.DMatrix(X_tr[selected_features], label=y_t, enable_categorical=True)\n",
    "    dval_sel = xgb.DMatrix(X_vl[selected_features], label=y_v, enable_categorical=True)\n",
    "    model_sel = xgb.train(params, dtrain_sel, num_boost_round=500, verbose_eval=False)\n",
    "    \n",
    "    try:\n",
    "        auc_sel = roc_auc_score(y_v, model_sel.predict(dval_sel))\n",
    "    except ValueError:\n",
    "        auc_sel = 0.5\n",
    "        \n",
    "    delta = auc_sel - auc_all\n",
    "    sign = \"+\" if delta >= 0 else \"\"\n",
    "    print(f\"{target:<15} {n_pos:>7} {auc_all:>10.4f} {auc_sel:>11.4f} {len(selected_features):>9} {sign}{delta:>7.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5852d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e7cc0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d53d774",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
