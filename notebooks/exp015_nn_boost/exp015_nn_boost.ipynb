{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXP-015: NN фабрика + Hill Climbing (LB 0.8527, рекорд!)\n",
    "\n",
    "**Базируется на EXP-014** (LB 0.8522)\n",
    "\n",
    "## Идея: \"фабрика NN\"\n",
    "Обучаем несколько NN с разной архитектурой/скалером → diversity → сильный бленд.\n",
    "\n",
    "## Результаты:\n",
    "| Версия | Архитектура | Scaler | Dropout | OOF |\n",
    "|--------|------------|--------|---------|-----|\n",
    "| v3 | 512→256→128 | StandardScaler | 0.30 | 0.8415 |\n",
    "| v4 | 512→256→128 | RankGauss | 0.30 + InputDrop 0.10 | 0.8426 |\n",
    "| v5 SWA | v4 + SWA | RankGauss | 0.30 | 0.8421 (ПРОВАЛ) |\n",
    "| **v6** | **1024→512→256** | **RankGauss** | **0.40** + InputDrop 0.10 | **0.8440** |\n",
    "\n",
    "## Финальный бленд:\n",
    "- Hill Climbing per-target (XGB + v3 + v4 + v6) → **OOF 0.8493** (+0.0012)\n",
    "- Средние веса: xgb=0.47, v3=0.20, v4=0.08, v6=0.25\n",
    "- **LB: 0.8527** (рекорд, +0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 1: Setup + Load EXP-014 artifacts\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from joblib import Parallel, delayed\n",
    "import gc, time, os, json\n",
    "from datetime import datetime\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "log_msg = lambda msg: print(f\"[{datetime.now().strftime('%H:%M:%S')}] {msg}\")\n",
    "\n",
    "# --- Пути (Drive папка = data_fusion, НЕ data_fusion_2026!) ---\n",
    "DATA = '/content/drive/MyDrive/data_fusion'\n",
    "ART_L1 = f'{DATA}/artifacts/l1_oof'\n",
    "ART_L2 = f'{DATA}/artifacts/l2_stacking'\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "N_FOLDS_L2 = 5\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# --- Таргеты (БЕЗ sorted! sorted ломает порядок столбцов → AUC=0.50) ---\n",
    "target = pd.read_parquet(f'{DATA}/train_target.parquet')\n",
    "target_cols = [c for c in target.columns if c.startswith('target_')]\n",
    "y_train_arr = target[target_cols].values.astype(np.int8)\n",
    "train_ids = target['customer_id'].values\n",
    "del target; gc.collect()\n",
    "print(f\"Targets: {y_train_arr.shape}, cols: {len(target_cols)}\")\n",
    "print(f\"Порядок: {target_cols[:3]} ... {target_cols[-2:]}\")\n",
    "\n",
    "# --- L1 OOF ---\n",
    "oof_xgb = np.load(f'{ART_L1}/oof_xgb.npy')\n",
    "oof_cb  = np.load(f'{ART_L1}/oof_cb.npy')\n",
    "oof_lgb = np.load(f'{ART_L1}/oof_lgb.npy')\n",
    "test_xgb = np.load(f'{ART_L1}/test_xgb.npy')\n",
    "test_cb  = np.load(f'{ART_L1}/test_cb.npy')\n",
    "test_lgb = np.load(f'{ART_L1}/test_lgb.npy')\n",
    "print(f\"L1 OOF: XGB {oof_xgb.shape}, CB {oof_cb.shape}, LGB {oof_lgb.shape}\")\n",
    "\n",
    "# --- L2 матрица (123 OOF + 82 meta = 205 features) ---\n",
    "X_l2_train = np.hstack([oof_xgb, oof_cb, oof_lgb])\n",
    "X_l2_test  = np.hstack([test_xgb, test_cb, test_lgb])\n",
    "oof_stack = np.stack([oof_xgb, oof_cb, oof_lgb], axis=0)\n",
    "test_stack = np.stack([test_xgb, test_cb, test_lgb], axis=0)\n",
    "X_l2_train = np.hstack([X_l2_train, oof_stack.mean(0), oof_stack.std(0)])\n",
    "X_l2_test  = np.hstack([X_l2_test, test_stack.mean(0), test_stack.std(0)])\n",
    "del oof_stack, test_stack; gc.collect()\n",
    "print(f\"L2 matrix: train {X_l2_train.shape}, test {X_l2_test.shape}\")\n",
    "\n",
    "# --- L2 XGB OOF (якорь) ---\n",
    "oof_l2_xgb = np.load(f'{ART_L2}/oof_l2_xgb.npy')\n",
    "test_l2_xgb = np.load(f'{ART_L2}/test_l2_xgb.npy')\n",
    "xgb_macro = np.mean([roc_auc_score(y_train_arr[:, i], oof_l2_xgb[:, i]) for i in range(41)])\n",
    "print(f\"L2 XGB OOF Macro AUC: {xgb_macro:.4f}\")\n",
    "\n",
    "# --- L2 NN v3 OOF (файл oof_l2_nn_v3.npy, НЕ oof_l2_nn.npy!) ---\n",
    "oof_l2_nn_v3 = np.load(f'{ART_L2}/oof_l2_nn_v3.npy')\n",
    "test_l2_nn_v3 = np.load(f'{ART_L2}/test_l2_nn_v3.npy')\n",
    "nn_v3_macro = np.mean([roc_auc_score(y_train_arr[:, i], oof_l2_nn_v3[:, i]) for i in range(41)])\n",
    "print(f\"L2 NN v3 OOF Macro AUC: {nn_v3_macro:.4f}\")\n",
    "\n",
    "# --- Blend baseline ---\n",
    "blend = 0.6 * oof_l2_xgb + 0.4 * oof_l2_nn_v3\n",
    "blend_macro = np.mean([roc_auc_score(y_train_arr[:, i], blend[:, i]) for i in range(41)])\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"BASELINE: XGB={xgb_macro:.4f}, NN_v3={nn_v3_macro:.4f}, Blend 60/40={blend_macro:.4f}\")\n",
    "print(f\"LB 0.8522\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 2: RankGauss + NN architectures\n",
    "# ============================================================\n",
    "\n",
    "# --- RankGauss ---\n",
    "log_msg(\"Fitting QuantileTransformer (RankGauss)...\")\n",
    "qt = QuantileTransformer(n_quantiles=1000, output_distribution='normal', random_state=RANDOM_SEED)\n",
    "X_train_rg = qt.fit_transform(X_l2_train).astype(np.float32)\n",
    "X_test_rg = qt.transform(X_l2_test).astype(np.float32)\n",
    "print(f\"RankGauss range: [{X_train_rg.min():.2f}, {X_train_rg.max():.2f}]\")\n",
    "\n",
    "# --- NN v4: 512→256→128 + RankGauss + Input Dropout ---\n",
    "class L2NetV4(nn.Module):\n",
    "    def __init__(self, in_dim=205, h1=512, h2=256, h3=128, n_targets=41,\n",
    "                 drop_input=0.10, drop1=0.3, drop2=0.25, drop3=0.2):\n",
    "        super().__init__()\n",
    "        self.input_drop = nn.Dropout(drop_input)\n",
    "        self.input_norm = nn.LayerNorm(in_dim)\n",
    "        self.fc1 = nn.Linear(in_dim, h1)\n",
    "        self.ln1 = nn.LayerNorm(h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.ln2 = nn.LayerNorm(h2)\n",
    "        self.skip_proj = nn.Linear(h1, h2)\n",
    "        self.fc3 = nn.Linear(h2, h3)\n",
    "        self.ln3 = nn.LayerNorm(h3)\n",
    "        self.classifier = nn.Linear(h3, n_targets)\n",
    "        self.drop1 = nn.Dropout(drop1)\n",
    "        self.drop2 = nn.Dropout(drop2)\n",
    "        self.drop3 = nn.Dropout(drop3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_drop(x)\n",
    "        x = self.input_norm(x)\n",
    "        h1 = self.drop1(F.silu(self.ln1(self.fc1(x))))\n",
    "        h2 = self.ln2(self.fc2(h1))\n",
    "        h2 = self.drop2(F.silu(h2 + self.skip_proj(h1) * 0.5))\n",
    "        h3 = self.drop3(F.silu(self.ln3(self.fc3(h2))))\n",
    "        return self.classifier(h3)\n",
    "\n",
    "# --- NN v6: 1024→512→256 + RankGauss + Higher Dropout ---\n",
    "class L2NetV6(nn.Module):\n",
    "    def __init__(self, in_dim=205, h1=1024, h2=512, h3=256, n_targets=41,\n",
    "                 drop_input=0.10, drop1=0.40, drop2=0.35, drop3=0.30):\n",
    "        super().__init__()\n",
    "        self.input_drop = nn.Dropout(drop_input)\n",
    "        self.input_norm = nn.LayerNorm(in_dim)\n",
    "        self.fc1 = nn.Linear(in_dim, h1)\n",
    "        self.ln1 = nn.LayerNorm(h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.ln2 = nn.LayerNorm(h2)\n",
    "        self.skip_proj = nn.Linear(h1, h2)\n",
    "        self.fc3 = nn.Linear(h2, h3)\n",
    "        self.ln3 = nn.LayerNorm(h3)\n",
    "        self.classifier = nn.Linear(h3, n_targets)\n",
    "        self.drop1 = nn.Dropout(drop1)\n",
    "        self.drop2 = nn.Dropout(drop2)\n",
    "        self.drop3 = nn.Dropout(drop3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_drop(x)\n",
    "        x = self.input_norm(x)\n",
    "        h1 = self.drop1(F.silu(self.ln1(self.fc1(x))))\n",
    "        h2 = self.ln2(self.fc2(h1))\n",
    "        h2 = self.drop2(F.silu(h2 + self.skip_proj(h1) * 0.5))\n",
    "        h3 = self.drop3(F.silu(self.ln3(self.fc3(h2))))\n",
    "        return self.classifier(h3)\n",
    "\n",
    "print(f\"L2NetV4 params: {sum(p.numel() for p in L2NetV4().parameters()):,}\")\n",
    "print(f\"L2NetV6 params: {sum(p.numel() for p in L2NetV6().parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 3: Train NN helper function\n",
    "# ============================================================\n",
    "\n",
    "def train_nn_l2(model_class, X_train_scaled, X_test_scaled, y_train_arr, target_cols,\n",
    "                n_folds=5, n_epochs=60, batch=512, lr=0.001, wd=1e-5, patience=15,\n",
    "                seed=42, label=\"NN\"):\n",
    "    \"\"\"Обучает NN L2, возвращает (oof, test, fold_aucs).\"\"\"\n",
    "    oof = np.zeros((len(X_train_scaled), 41), dtype=np.float32)\n",
    "    test_preds = np.zeros((len(X_test_scaled), 41), dtype=np.float32)\n",
    "    X_te = torch.FloatTensor(X_test_scaled).to(device)\n",
    "    y_all = torch.FloatTensor(y_train_arr.astype(np.float32))\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "    fold_aucs = []\n",
    "    t_total = time.time()\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{label}: {n_folds}-fold, {n_epochs} ep, patience={patience}, batch={batch}, lr={lr}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(skf.split(X_train_scaled, y_train_arr[:, 0])):\n",
    "        t0 = time.time()\n",
    "        X_tr = torch.FloatTensor(X_train_scaled[tr_idx]).to(device)\n",
    "        y_tr = y_all[tr_idx].to(device)\n",
    "        X_val = torch.FloatTensor(X_train_scaled[val_idx]).to(device)\n",
    "        train_dl = DataLoader(TensorDataset(X_tr, y_tr), batch_size=batch, shuffle=True)\n",
    "\n",
    "        model = model_class().to(device)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer, max_lr=lr, epochs=n_epochs,\n",
    "            steps_per_epoch=len(train_dl), pct_start=0.3)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        best_auc = 0; best_state = None; no_improve = 0\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            model.train()\n",
    "            for xb, yb in train_dl:\n",
    "                optimizer.zero_grad()\n",
    "                loss = criterion(model(xb), yb)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_probs = torch.sigmoid(model(X_val)).cpu().numpy()\n",
    "            aucs = [roc_auc_score(y_train_arr[val_idx, j], val_probs[:, j]) for j in range(41)]\n",
    "            macro = np.mean(aucs)\n",
    "            if macro > best_auc:\n",
    "                best_auc = macro\n",
    "                best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "                no_improve = 0\n",
    "            else:\n",
    "                no_improve += 1\n",
    "\n",
    "            if (epoch + 1) % 10 == 0 or no_improve >= patience:\n",
    "                log_msg(f\"  Fold {fold} ep {epoch+1}: AUC={macro:.4f} (best={best_auc:.4f}, no_imp={no_improve})\")\n",
    "            if no_improve >= patience:\n",
    "                break\n",
    "\n",
    "        model.load_state_dict(best_state)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            oof[val_idx] = torch.sigmoid(model(X_val)).cpu().numpy()\n",
    "            test_preds += torch.sigmoid(model(X_te)).cpu().numpy() / n_folds\n",
    "\n",
    "        fold_aucs.append(best_auc)\n",
    "        log_msg(f\"Fold {fold}: AUC={best_auc:.4f}, time={time.time()-t0:.0f}s\")\n",
    "        del X_tr, y_tr, X_val, model, optimizer, scheduler, best_state\n",
    "        torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "    macro = np.mean([roc_auc_score(y_train_arr[:, i], oof[:, i]) for i in range(41)])\n",
    "    print(f\"\\n{label} OOF Macro AUC: {macro:.4f}\")\n",
    "    print(f\"Per-fold: {[f'{a:.4f}' for a in fold_aucs]}\")\n",
    "    print(f\"Total: {(time.time()-t_total)/60:.1f} min\")\n",
    "    return oof, test_preds, fold_aucs\n",
    "\n",
    "print(\"train_nn_l2() ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 4: Train NN v4 (SKIP if artifact exists)\n",
    "# ============================================================\n",
    "\n",
    "if os.path.exists(f'{ART_L2}/oof_l2_nn_v4.npy'):\n",
    "    print(\">>> NN v4: SKIP (артефакты найдены) <<<\")\n",
    "    oof_l2_nn_v4 = np.load(f'{ART_L2}/oof_l2_nn_v4.npy')\n",
    "    test_l2_nn_v4 = np.load(f'{ART_L2}/test_l2_nn_v4.npy')\n",
    "    v4_macro = np.mean([roc_auc_score(y_train_arr[:, i], oof_l2_nn_v4[:, i]) for i in range(41)])\n",
    "    print(f\"  OOF Macro AUC: {v4_macro:.4f}\")\n",
    "else:\n",
    "    oof_l2_nn_v4, test_l2_nn_v4, _ = train_nn_l2(\n",
    "        L2NetV4, X_train_rg, X_test_rg, y_train_arr, target_cols, label=\"NN v4\")\n",
    "    np.save(f'{ART_L2}/oof_l2_nn_v4.npy', oof_l2_nn_v4)\n",
    "    np.save(f'{ART_L2}/test_l2_nn_v4.npy', test_l2_nn_v4)\n",
    "    print(f\"Saved to {ART_L2}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 5: Train NN v6 Wider (SKIP if artifact exists)\n",
    "# ============================================================\n",
    "\n",
    "if os.path.exists(f'{ART_L2}/oof_l2_nn_v6.npy'):\n",
    "    print(\">>> NN v6: SKIP (артефакты найдены) <<<\")\n",
    "    oof_l2_nn_v6 = np.load(f'{ART_L2}/oof_l2_nn_v6.npy')\n",
    "    test_l2_nn_v6 = np.load(f'{ART_L2}/test_l2_nn_v6.npy')\n",
    "    v6_macro = np.mean([roc_auc_score(y_train_arr[:, i], oof_l2_nn_v6[:, i]) for i in range(41)])\n",
    "    print(f\"  OOF Macro AUC: {v6_macro:.4f}\")\n",
    "else:\n",
    "    oof_l2_nn_v6, test_l2_nn_v6, _ = train_nn_l2(\n",
    "        L2NetV6, X_train_rg, X_test_rg, y_train_arr, target_cols, label=\"NN v6 Wider\")\n",
    "    np.save(f'{ART_L2}/oof_l2_nn_v6.npy', oof_l2_nn_v6)\n",
    "    np.save(f'{ART_L2}/test_l2_nn_v6.npy', test_l2_nn_v6)\n",
    "    print(f\"Saved to {ART_L2}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 6: N-way blend + Hill Climbing + Submission\n",
    "# ============================================================\n",
    "\n",
    "baseline_2way = np.mean([roc_auc_score(y_train_arr[:, i],\n",
    "    (0.6*oof_l2_xgb + 0.4*oof_l2_nn_v3)[:, i]) for i in range(41)])\n",
    "print(f\"Baseline 2-way (EXP-014): {baseline_2way:.4f}\")\n",
    "\n",
    "# === N-way бленды ===\n",
    "print(f\"\\n=== N-way бленды ===\")\n",
    "best_auc = 0; best_w = None\n",
    "for w_xgb in [0.45, 0.50, 0.55, 0.60]:\n",
    "    for w_v3 in [0.00, 0.05, 0.10, 0.15]:\n",
    "        for w_v4 in [0.00, 0.05, 0.10, 0.15]:\n",
    "            w_v6 = round(1.0 - w_xgb - w_v3 - w_v4, 2)\n",
    "            if w_v6 < 0.10 or w_v6 > 0.45:\n",
    "                continue\n",
    "            bl = w_xgb*oof_l2_xgb + w_v3*oof_l2_nn_v3 + w_v4*oof_l2_nn_v4 + w_v6*oof_l2_nn_v6\n",
    "            auc = np.mean([roc_auc_score(y_train_arr[:, i], bl[:, i]) for i in range(41)])\n",
    "            if auc > best_auc:\n",
    "                best_auc = auc; best_w = (w_xgb, w_v3, w_v4, w_v6)\n",
    "            if auc > baseline_2way + 0.0005:\n",
    "                print(f\"  XGB={w_xgb} v3={w_v3} v4={w_v4} v6={w_v6} -> {auc:.5f} ({auc-baseline_2way:+.5f})\")\n",
    "\n",
    "print(f\"\\nЛучший fixed: XGB={best_w[0]} v3={best_w[1]} v4={best_w[2]} v6={best_w[3]} -> {best_auc:.5f}\")\n",
    "\n",
    "# === Hill Climbing per-target (параллельный!) ===\n",
    "print(f\"\\n=== Hill Climbing per-target ===\")\n",
    "\n",
    "def hill_climb_target(i):\n",
    "    \"\"\"Ищет лучшие веса для одного таргета.\"\"\"\n",
    "    y_col = y_train_arr[:, i]\n",
    "    best_auc_t = 0; best_w_t = None\n",
    "    for w_xgb in np.arange(0.3, 0.71, 0.05):\n",
    "        for w_v6 in np.arange(0.15, 0.51, 0.05):\n",
    "            remainder = 1.0 - w_xgb - w_v6\n",
    "            if remainder < 0:\n",
    "                continue\n",
    "            for w_v4 in np.arange(0, remainder + 0.01, 0.05):\n",
    "                w_v3 = round(remainder - w_v4, 2)\n",
    "                if w_v3 < 0 or w_v3 > 0.3:\n",
    "                    continue\n",
    "                bl = (w_xgb * oof_l2_xgb[:, i] + w_v3 * oof_l2_nn_v3[:, i] +\n",
    "                      w_v4 * oof_l2_nn_v4[:, i] + w_v6 * oof_l2_nn_v6[:, i])\n",
    "                auc = roc_auc_score(y_col, bl)\n",
    "                if auc > best_auc_t:\n",
    "                    best_auc_t = auc\n",
    "                    best_w_t = (round(w_xgb, 2), round(w_v3, 2), round(w_v4, 2), round(w_v6, 2))\n",
    "    return i, target_cols[i], best_w_t, best_auc_t\n",
    "\n",
    "results = Parallel(n_jobs=-1, verbose=1)(delayed(hill_climb_target)(i) for i in range(41))\n",
    "\n",
    "oof_hill = np.zeros((len(y_train_arr), 41), dtype=np.float64)\n",
    "test_hill = np.zeros((250000, 41), dtype=np.float64)\n",
    "per_target_weights = {}\n",
    "\n",
    "for i, tc, w, auc in results:\n",
    "    oof_hill[:, i] = w[0]*oof_l2_xgb[:, i] + w[1]*oof_l2_nn_v3[:, i] + w[2]*oof_l2_nn_v4[:, i] + w[3]*oof_l2_nn_v6[:, i]\n",
    "    test_hill[:, i] = w[0]*test_l2_xgb[:, i] + w[1]*test_l2_nn_v3[:, i] + w[2]*test_l2_nn_v4[:, i] + w[3]*test_l2_nn_v6[:, i]\n",
    "    per_target_weights[tc] = {'xgb': w[0], 'v3': w[1], 'v4': w[2], 'v6': w[3], 'auc': auc}\n",
    "\n",
    "hill_macro = np.mean([roc_auc_score(y_train_arr[:, i], oof_hill[:, i]) for i in range(41)])\n",
    "print(f\"\\nHill Climbing OOF: {hill_macro:.5f} (vs baseline {baseline_2way:.5f}, diff={hill_macro-baseline_2way:+.5f})\")\n",
    "\n",
    "import collections\n",
    "w_stats = collections.Counter()\n",
    "for tc, w in per_target_weights.items():\n",
    "    dominant = max(w, key=lambda k: w[k] if k != 'auc' else 0)\n",
    "    w_stats[dominant] += 1\n",
    "print(f\"Доминантная модель: {dict(w_stats)}\")\n",
    "avg_w = {k: np.mean([per_target_weights[tc][k] for tc in target_cols]) for k in ['xgb', 'v3', 'v4', 'v6']}\n",
    "print(f\"Средние веса: {', '.join(f'{k}={v:.2f}' for k, v in avg_w.items())}\")\n",
    "\n",
    "# === Submission ===\n",
    "print(f\"\\n=== Submission ===\")\n",
    "test_df = pd.read_parquet(f'{DATA}/test_main_features.parquet', columns=['customer_id'])\n",
    "sub = pd.DataFrame({'customer_id': test_df['customer_id'].values})\n",
    "for i, tc in enumerate(target_cols):\n",
    "    sub[tc.replace('target_', 'predict_')] = test_hill[:, i].astype(np.float64)\n",
    "\n",
    "assert sub.shape == (250000, 42)\n",
    "assert sub.iloc[:, 1:].dtypes.unique()[0] == np.float64\n",
    "\n",
    "out_path = f'{DATA}/submission_exp015_hill_climb.parquet'\n",
    "sub.to_parquet(out_path, index=False)\n",
    "print(f\"Сохранено: {out_path}\")\n",
    "print(f\"Hill Climbing OOF: {hill_macro:.5f} → LB: 0.8527\")\n",
    "\n",
    "# Save artifacts\n",
    "with open(f'{ART_L2}/hill_climb_weights.json', 'w') as f:\n",
    "    json.dump(per_target_weights, f, indent=2)\n",
    "print(\"hill_climb_weights.json saved!\")\n",
    "\n",
    "del test_df; gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}