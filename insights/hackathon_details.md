# Data Fusion 2026 — Cybershelf: Полные детали

## Описание задачи
Задача 2 "Киберполка" — рекомендательная система финансовых продуктов ВТБ.
Нужно предсказать вероятность открытия клиентом каждого из 41 продукта.
Это multi-label задача: клиент может открыть несколько продуктов одновременно.

## Структура данных

### Train (750 000 записей)
- `customer_id` — идентификатор клиента
- `cat_feature_0`...`cat_feature_N` — категориальные признаки
- `num_feature_0`...`num_feature_N` — числовые признаки
- 41 целевая переменная (бинарные: открыл/не открыл продукт)

### Test (250 000 записей)
- Те же признаки, без целевых переменных

### Дополнительные признаки
- 2000+ признаков доступны отдельным набором
- Могут значительно улучшить результат

## Особенности данных
- Полная анонимизация и обфускация — невозможно понять бизнес-смысл признаков
- Значительные пропуски (NaN)
- Выбросы в числовых признаках
- Дисбаланс классов весьма вероятен (финансовые продукты)

## Формат сабмита
Файл `submit.parquet`:
```
customer_id | predict_1_1 | predict_1_2 | ... | predict_10_1
1750000     | -4.921889   | -5.700829   | ... | -3.456789
```
- 42 столбца: customer_id + 41 предсказание
- Значения — вещественные числа (логиты)
- Пример: `sample_submit.parquet` на странице данных

## Метрика
```python
from sklearn.metrics import roc_auc_score
score = roc_auc_score(y_true, y_pred, average="macro")
```
Macro = простое среднее ROC-AUC по каждому из 41 класса.
Важно: слабые классы (редкие продукты) весят столько же, сколько частые.

## Лидерборд
- Public: 75 000 записей (30%) — видим во время соревнования
- Private: 175 000 записей (70%) — финальная оценка
- Можно выбрать до 2 решений для private лидерборда

## Лимиты
- Команда: до 4 человек
- Сабмитов в день: 5
- Сабмитов всего: 300
- Призы: только на счета банков РФ

## Сроки
- Старт: 9 февраля 2026
- Финиш: 30 марта 2026
- Награждение: конференция Data Fusion 8-9 апреля 2026

## Типичные подходы для таких задач
- Gradient Boosting (LightGBM, CatBoost, XGBoost) — основа
- Feature engineering на обфусцированных данных (статистики, взаимодействия)
- Обработка пропусков (native handling в бустингах)
- Multi-label: 41 отдельная модель или shared-bottom архитектура
- Блендинг/стекинг для финального решения
- Neural networks (TabNet, FT-Transformer) как дополнение к бустингам
